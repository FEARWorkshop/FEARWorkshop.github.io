<!DOCTYPE html>
<html lang="en-gb">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
        Formal Ethical Agents and Robots — FEAR 2024
    </title>
    <meta name="description"
        content="Information about the Formal Ethical Agents and Robots workshop (FEAR) 2024.">

    <link rel="stylesheet" type="text/css" href="styles/dropdown.css" />
    <link rel="stylesheet" type="text/css" href="styles/fonts.css" />
    <link rel="stylesheet" type="text/css" href="styles/highlight.css" />
    <link rel="stylesheet" type="text/css" href="styles/main.css" />
    <link rel="stylesheet" type="text/css" href="styles/navbar.css" />
    <link rel="stylesheet" type="text/css" href="styles/normalize.css" />
    <link rel="stylesheet" type="text/css" href="styles/program.css" />
    <link rel="stylesheet" type="text/css" href="styles/speaker.css" />
    <link rel="stylesheet" type="text/css" href="styles/tables.css" />
    <link rel="stylesheet" type="text/css" href="main.css" />
    <link rel="preload" fetchpriority="high" as="image" href="media/pexels-szymon-shields-11210304-compressed.jpg"
        type="image/jpeg">

    <!--
    Does nothing, but prevents flash of unstyled content in Firefox.
    Thanks: https://stackoverflow.com/a/64158043
  -->
    <script>
        let fix_FOUC_in_firefox;
    </script>

</head>

<body>
    <div class="fancy" id="header">
        <div id="nav-container">
            <!-- <div id="navbar" role="navigation"><a href="/">Home</a><a href="/program.html">Program</a><a
                    href="/venue.html">Venue</a>
                <a class="desktop-only" href="/workshops.html">Workshops</a><a class="desktop-only"
                    href="/registration.html">Registration</a>

                <label id="menu-dropdown">
                    <div id="dropdown-button">More</div>

                    <input id="dropdown-input" type="checkbox" />

                    <ul id="dropdown-menu">
                        <li class="mobile-only"><a href="workshops.html">Workshops</a></li>
                        <li class="mobile-only"><a href="registration.html">Registration</a></li>
                        <li><a href="accepted-papers.html">Accepted Papers</a></li>
                        <li><a href="artifacts.html">Call for Artifacts</a></li>
                        <li><a href="submissions.html">Submissions</a></li>
                        <li><a href="organisation.html">Organisation</a></li>
                        <li><a href="contact.html">Contact</a></li>
                    </ul>
                </label>
            </div> -->
        </div>

        <div id="title-block" title="Photo by Szymon Shields">
            <h1><span><a href="/" title="Go to home page">FEAR 2024<span style="font-size: 0.8em"> </span></a></span>
            </h1>

            <div id="subtitle"><span>Formal Ethical Agents and Robots — FEAR</span></div>
        </div>
    </div>

    <div id="doc" role="main">
        <h2 id="workshop-location" class="section"><a class="anchor" href="#workshop-location"
                title="permalink to this section">Workshop Location</a></h2>
        <p>The workshop will be in the Rutherford Rooms in the Core Technology Facility.</p>
        <h2 id="program" class="section"><a class="anchor" href="#program" title="permalink to this section">Program —
                Monday, <span style="white-space: nowrap">11 Nov 2024</span></a></h2>
        <div class="program" paragraphs="none">
            <div class="day">
                <div class="item">
                    <div class="time">11:00–12:30</div>
                    <div class="item-text">Workshop participants are invited to attend the FMAS Keynote talk by Silvia
                        Lizeth Tapia Tarifa.</div>
                </div>
                <div class="item">
                    <div class="time">12:30–13:30</div>
                    <div class="item-text">Lunch</div>
                </div>
                <div class="item">
                    <div class="time">13:30–14:30</div>
                    <div class="item-text">Keynote Talk
                        <div><a class="extlink " href="#marija-slavkovik-speaker-info"><strong>Understanding Privacy by
                                    Formalising It</strong></a><br /> <em>Marija Slavkovik, University of Bergen</em>
                        </div>
                    </div>
                </div>
                <div class="item">
                    <div class="time">14:30–15:00</div>
                    <div class="item-text">
                        <div><strong>Acting for the Right Reasons: Creating Reason-Sensitive Artificial Moral
                                Agents</strong><br /> <em>Kevin Baum et al.</em></div>
                    </div>
                </div>
                <div class="item">
                    <div class="time">15:00–15:30</div>
                    <div class="item-text">Coffee Break</div>
                </div>
                <div class="item">
                    <div class="time">15:30–16:20</div>
                    <div class="item-text">
                        <div><strong>From Responsibility, via Indifference, to Recklessness</strong><br /> <em>Michael
                                Fisher</em></div>
                        <div><strong>The Need for Formal Specifications of Morally Relevant Information for Algorithmic
                                Decision-Making</strong> <span style="white-space: nowrap">(short paper)</span><br />
                            <em>Marija Slavkovik</em></div>
                    </div>
                </div>
                <div class="item">
                    <div class="time">16:20</div>
                    <div class="item-text">Community Discussion</div>
                </div>
            </div>
        </div>
        <h2 id="keynote-speaker" class="section"><a class="anchor" href="#keynote-speaker"
                title="permalink to this section">Keynote Speaker</a></h2>
        <div class="invited-speaker" id="marija-slavkovik-speaker-info">
            <div class="title-name-affiliation">
                <div class="talk-title">Understanding Privacy by Formalising It</div>
                <div class="name-affiliation">
                    <div class="name"><a href="http://slavkovik.com/">Marija Slavkovik</a></div>
                    <div class="affiliation">University of Bergen, Norway</div>
                </div>
            </div>
            <div class="info-and-image">
                <div class="info-container">
                    <div class="talk-abstract" paragraphs="none"><span>Abstract</span>
                        <p>In most of the modern societies, there is a broad consensus regarding the need for promoting
                            privacy and thus placing restrictions on technological—including AI—developments to protect
                            people’s right to privacy. In order to meet these expectations on the algorithmic level,
                            first we need to make the concept of privacy and the related or derived rights formally
                            specified. However, the notion of (the right to) privacy is subject to different
                            interpretations. In the context of ethical impact of artificial intelligence, privacy is
                            often discussed as a value eroded by digitization and artificial intelligence. Privacy,
                            however, is not one of the traditional moral values, but rather a social value. There are
                            numerous attempts in the literature on defining privacy, but there is no consensus. The
                            overall privacy situation is made more confusing by the “emerging personal data economy”.
                            The data economy both exploits and drives the need for more specific privacy regulations.
                            Algorithmic processes run faster and are more ubiquitous than human processing capabilities.
                            If privacy were a right to be guaranteed to users of digital technologies, we need to
                            understand its specific scope, motivation and eligible trade-offs. If privacy were a value
                            with which we need to align those algorithmic processes, we need to specify it
                            mathematically to the level that we can construct an algorithm that detects whether privacy
                            is violated. We discuss initial attempts at using a multi-modal logic to provide an initial
                            formalization of different theories and approaches’ basic principles and their implications
                            investigating the right to privacy as an epistemic right within the theory of normative
                            positions.</p>
                    </div>
                    <div class="speaker-bio">
                        <figure class="headshot-container"><img src="https://i.imgur.com/GUsf9Rc.png"
                                alt="Marija Slavkovik" title="Marija Slavkovik" />
                            <figcaption><a href="http://slavkovik.com/">Marija Slavkovik</a></figcaption>
                        </figure>
                        <div class="bio-text" paragraphs="none"><span>Biography</span>
                            <p>Marija Slavkovik is a Professor with the Faculty for Social Sciences of the University of
                                Bergen. Her background is in computer science and artificial intelligence. She has been
                                doing research in machine ethics since 2012. Machine ethics studies how moral reasoning
                                can or should be automated. Marija works on formalising ethical collective
                                decision-making. She has held held several seminars, tutorials and graduate courses on
                                AI ethics (<a
                                    href="https://slavkovik.com/teaching.html">https://slavkovik.com/teaching.html</a>).
                                Marija is a vice-chair of the the Norwegian AI Association, board member of European
                                Association for Artificial Intelligence, a member of the informal advisory group on
                                Ethics, Legal, Social Issues (ELS) of CLAIRE, in the editorial board of AI Magazine, and
                                AI and Society track editor of JAIR. She is the current chair of the department of
                                information science and media studies that since 2021 has been offering, in
                                collaboration with the department of informatics the first bachelor program in AI in
                                Norway.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <h2 id="overview" class="section"><a class="anchor" href="#overview"
                title="permalink to this section">Overview</a></h2>
        <p>Recent advances in artificial intelligence have led to a range of concerns about the ethical impact of the
            technology. This includes concerns about the day-to-day behaviour of robotic systems that will interact with
            humans in workplaces, homes and hospitals. One of the themes of these concerns is the need for such systems
            to take ethics into account when reasoning. This has generated new interest in how we can specify, implement
            and validate ethical reasoning. The aim of this workshop would be to look at formal approaches to these
            questions. Topics of interest include but are not limited to:</p>
        <ul>
            <li>Logics for morality and ethics</li>
            <li>Knowledge representation of ethical theories and ethically salient information</li>
            <li>Computational modelling of morality and ethics</li>
            <li>Specification of ethical reasoning and behaviour</li>
            <li>Verification of ethical reasoning and behaviour</li>
            <li>Formal modelling of ethical accountability</li>
        </ul>
        <h2 id="submission-information" class="section"><a class="anchor" href="#submission-information"
                title="permalink to this section">Submission Information</a></h2>
        <p>We will accept three types of paper prepared using the EPTCS LaTeX style.</p>
        <ul class="loose-list">
            <li>Regular papers describing completed research (up to 16 pages in length).</li>
            <li>Short papers describing work-in-progress or directions for future work (up to 8 pages in length).</li>
            <li>Abstracts providing a high-level description of some research published (or submitted/intended for
                publication) elsewhere (up to 2 pages in length).</li>
        </ul>
        <p>Papers should be submitted using <a class="extlink emphasised"
                href="https://openreview.net/group?id=manchester.ac.uk/University_of_Manchester/iFM/2024/Workshop/FEAR">OpenReview</a>.
            The paper type should be included as part of the paper title. Reviews will be single-blind. Please note that
            OpenReview can take up to two weeks to approve a new profile registration that does not contain an
            institution email address.</p>
        <p>We intend to host informal workshop proceedings on OpenReview.</p>
        <h2 id="important-dates" class="section"><a class="anchor" href="#important-dates"
                title="permalink to this section">Important Dates</a></h2>
        <ul>
            <li>Submission Deadline: Thursday, 8th August, 11:59 UTC-0</li>
            <li>Notification: Thursday, 12th September</li>
            <li>Workshop: 11th November</li>
        </ul>
        <h2 id="schedule-and-location" class="section"><a class="anchor" href="#schedule-and-location"
                title="permalink to this section">Schedule and Location</a></h2>
        <p>This will be a half day workshop with informal proceedings, consisting of short talks and opportunities for
            discussion. The workshop will be in the Rutherford Rooms in the Core Technology Facility.</p>
        <h2 id="program-chair" class="section"><a class="anchor" href="#program-chair"
                title="permalink to this section">Program Chair</a></h2>
        <div class="one-item-list"><strong>Louise Dennis</strong>, University of Manchester</div>
        <h2 id="program-committee" class="section"><a class="anchor" href="#program-committee"
                title="permalink to this section">Program Committee</a></h2>
        <ul>
            <li><strong>Kevin Baum</strong>, DFKI</li>
            <li><strong>Andreas Brännström</strong>, Umeå University</li>
            <li><strong>Ilaria Canavotto</strong>, University of Maryland</li>
            <li><strong>Sarah Christensen</strong>, University of Leeds</li>
            <li><strong>Joe Collenette</strong>, University of Chester</li>
            <li><strong>Alex Jackson</strong>, Kings College London</li>
            <li><strong>Aleks Knoks</strong>, University of Luxembourg</li>
            <li><strong>Simon Kolker</strong>, University of Manchester</li>
            <li><strong>Lara Lawnicza</strong>, University of Bamberg</li>
            <li><strong>Vivek Nallur</strong>, University College Dublin</li>
            <li><strong>Samer Nashed</strong>, University of Montreal</li>
            <li><strong>Maurice Pagnucco</strong>, University of New South Wales</li>
            <li><strong>Luca Pasetto</strong>, University of Luxembourg</li>
            <li><strong>Jazon Szabo</strong>, Kings College London</li>
            <li><strong>Rajitha Ramanayake</strong>, University College Dublin</li>
            <li><strong>Maike Schwammberger</strong>, Karlsruhe Institute of Technology</li>
            <li><strong>Marija Slavkovik</strong>, University of Bergen</li>
            <li><strong>Dieter Vanderelst</strong>, University of Cincinnati</li>
            <li><strong>Gleifer Vaz Alves</strong>, Federal University of Technology – Paraná</li>
            <li><strong>Andrea Vestrucci</strong>, University of Bamberg</li>
        </ul>
    </div>

    <div class="horizontal-rule"></div>
    <div id="footer">
        <div class="copyright">© FEAR 2025</div>
        ⋅
        <div class="logos"><img src="media/uom.png" title="University of Manchester" />
            <img src="media/rae.png" title="Royal Academy of Engineering" />
            <img src="media/kcl.png" title="King’s College London" />
        </div>
    </div>
</body>

</html>