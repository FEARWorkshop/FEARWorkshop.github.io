<!DOCTYPE html>
<html lang="en-gb">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
        Formal Ethical Agents and Robots — FEAR 2025
    </title>
    <meta name="description"
        content="Information about the Formal Ethical Agents and Robots workshop (FEAR) 2025.">

    <link rel="stylesheet" type="text/css" href="/styles/dropdown.css" />
    <link rel="stylesheet" type="text/css" href="/styles/fonts.css" />
    <link rel="stylesheet" type="text/css" href="/styles/highlight.css" />
    <link rel="stylesheet" type="text/css" href="/styles/main.css" />
    <link rel="stylesheet" type="text/css" href="/styles/navbar.css" />
    <link rel="stylesheet" type="text/css" href="/styles/normalize.css" />
    <link rel="stylesheet" type="text/css" href="/styles/program.css" />
    <link rel="stylesheet" type="text/css" href="/styles/speakers.css" />
    <link rel="stylesheet" type="text/css" href="/styles/tables.css" />
    <link rel="stylesheet" type="text/css" href="/styles/2025/main.css" />
    <link rel="preload" fetchpriority="high" as="image" href="/media/2025/nancy_rothwell.jpeg"
        type="image/jpeg">
    <!--
    Does nothing, but prevents flash of unstyled content in Firefox.
    Thanks: https://stackoverflow.com/a/64158043
  -->
    <script>
        let fix_FOUC_in_firefox;
    </script>

</head>

<body>
    <div class="fancy" id="header">
        <div id="nav-container">
            <div id="navbar" role="navigation">
                <a href="/2025/tutorial/">Home</a>
                <!-- <a href="#schedule-and-location">Venue</a> -->
                <!-- <a href="#program">Program</a> -->
                <a href="#tutors">Tutors</a>
                <a href="#submission-information">Submission</a>
                <a href="#program-chair">Organizers</a>
                <a href="/2025/workshop/">Workshop</a>
            </div>
        </div>

        <div id="title-block">
            <h1><span><a href="/2025/tutorial/" title="Go to home page">FEAR 2025<span style="font-size: 0.8em"> </span></a></span>
            </h1>

            <div id="subtitle"><span>Formal Ethical Agents and Robots Tutorial</span></div>
        </div>
    </div>

    <div id="doc" role="main">
        
        <h2 id="welcome" class="section"><a class="anchor" href="#welcome"
            title="permalink to this section">Welcome to FEAR 2025</a></h2>
        <p>The Second International Workshop on Formal Ethical Agents and Robots (FEAR) will be held on 4 November 2025 
            with co-located tutorial scheduled for 3 November 2025 both at the Kilburn Building, the University of Manchester, UK.
            <!-- <br><br> -->
            <!-- Online participation can be accessed via this <a href="https://teams.microsoft.com/l/meetup-join/19%3ameeting_NTM3YzNlZWEtNzJkZi00Y2IxLTgyMzgtNzczZDg2ODI2ZmZm%40thread.v2/0?context=%7b%22Tid%22%3a%22c152cb07-614e-4abb-818a-f035cfa91a77%22%2c%22Oid%22%3a%227bfb7636-6867-47c7-bede-81587fb144e3%22%7d">link</a> -->
            <!-- The registration is now open via this <a href="https://docs.google.com/forms/d/e/1FAIpQLSdHqscjYW14rdKTWH-TZ7Tw8WMA0Oybdyh4UV1GOytQPerbKQ/viewform?usp=header">link</a> -->
        </p>

        <h2 id="overview" class="section"><a class="anchor" href="#overview"
            title="permalink to this section">Overview</a></h2>
        <p> Machine ethics, the field where most work on formal ethical agents and robots is found, is in general concerned with equipping 
            autonomous intelligent agents with explicit moral reasoning capability. This problem offers many challenges and requires many 
            minds form different disciplines. As part of planned activities within the Distinguished International Associates program with 
            the <a href="https://raeng.org.uk/programmes-and-prizes/programmes/international-programmes/distinguished-international-associates/awardees/">Royal Academy of Engineering</a>
            we would like to  consolidate and enlarge the field of formal methods for machine ethics within the UK.
            To this end we are offering this tutorial, collocated with the The Second International Workshop on Formal Ethical Agents and 
            Robots (FEAR)
        </p>
        <h2 id="schedule-and-location" class="section"><a class="anchor" href="#schedule-and-location"
            title="permalink to this section">Schedule and Location</a></h2>
        <p>TThis year we will hold a free one-day workshop with informal proceedings, consisting of short talks and opportunities for
            discussion, and a free one-day tutorial that engages conversation in the state-of-the-art machine ethics fields. 
            The workshop and tutorial will be held at Atlas room, the first floor of the Kilburn Building, the University of Manchester on the Oxford Road, M13 9PL.
            The best way to enter and leave the building is through the entrance on the North side of the building.
            See the map of the first floor below.
            <img src="/media/2025/map_kilburn.png" width="100%" style="overflow: hidden;">
            <br><br>
            FEAR will be a hybrid meeting, supporting both virtual and in-person attendance. We strongly encourage in-person attendance.<br>
            <table>
                <tr>Tutorial Schedule 3rd of November 2025</tr>
                <tr><td>11:00</td><td>Welcome</td></tr>
                <tr><td>11:15</td><td><a href="/media/2025/slides-marija.pdf" target=”_blank”>What is Machine Ethics - Marija Slavkovik, University of Bergen</a></td></tr>
                <tr><td>12:15</td><td>Lunch</td></tr>
                <tr><td>13:00</td><td><a href="/media/2025/slides-marina.pdf" target=”_blank”>Normative Multi-Agent Systems: An Introduction - Marina de Vos, University of Bath</a></td></tr>
                <tr><td>14:00</td><td><a href="/media/2025/slides-logan.pdf" target=”_blank”>Reward Machines and Norms - Brian Logan, University of Aberdeen</a></td></tr>
                <tr><td>15:00</td><td>Coffee</td></tr>
                <tr><td>15:30</td><td><a href="/media/2025/slides-louise.pdf" target=”_blank”>Evaluating Machine Ethics - Louise Dennis, University of Manchester</a></td></tr>
            </table>
            <table>
                <tr>Workshop Schedule 4th of November 2025</tr>
                <tr><td>10:00</td><td>Welcome</td></tr>
                <tr><td>10:15</td><td><a href="/media/2025/slides-vivek.pdf" target=”_blank”>Keynote Talk: What Virtues Should a Care Robot Possess? Some Simulation Experiments and Human Results - Vivek Nallur, University College Dublin</a></td></tr>
                <tr><td>11:15</td><td>Coffee</td></tr>
                <tr><td>11:45</td><td><a href="/media/2025/Lerma and Penaloza.pdf" target=”_blank”>NAEL: Non-Antropocentric Ethical Logic (Short Paper) - Bianca Maria Lerma and Rafael Penaloza</a></td></tr>
                <tr><td>12:00</td><td>Lunch</td></tr>
                <tr><td>13:00</td><td><a href="/media/2025/slides-marina.pdf" target=”_blank”>Keynote Talk: Evolving Normative Systems: Adapt or Become Irrelevant - Marina de Vos, University of Bath</a></td></tr>
                <tr><td>15:00</td><td>Coffee</td></tr>
                <tr><td>15:30</td><td><a href="/media/2025/Farjami.pdf" target=”_blank”>Four Freedoms for Deontic Logic: A Framework for Scalable AI Ethics - Ali Farjami</a></td></tr>
                <tr><td>16:00</td><td><a href="/media/2025/Muskalla.pdf" target=”_blank”>Causal Anticipation for Reason-Based AI Alignment (Short Paper) - Yannic Muskalla</a></td></tr>
                <tr><td>16:15</td><td>Community Discussion</td></tr>
                <tr><td>17:00</td><td>Close</td></tr>
            </table>
        </p>
        
        <!-- <h2 id="workshop-location" class="section"><a class="anchor" href="#workshop-location"
                title="permalink to this section">Workshop Location</a></h2>
        <p>The workshop will be in the Nancy Rothwell Building, the University of Manchester.</p> -->
        <!-- <h2 id="program" class="section"><a class="anchor" href="#program" title="permalink to this section">Program —
                Monday, <span style="white-space: nowrap">11 Nov 2024</span></a></h2>
        <div class="program" paragraphs="none">
            <div class="day">
                <div class="item">
                    <div class="time">11:00–12:30</div>
                    <div class="item-text">Workshop participants are invited to attend the FMAS Keynote talk by Silvia
                        Lizeth Tapia Tarifa.</div>
                </div>
                <div class="item">
                    <div class="time">12:30–13:30</div>
                    <div class="item-text">Lunch</div>
                </div>
                <div class="item">
                    <div class="time">13:30–14:30</div>
                    <div class="item-text">Keynote Talk
                        <div><a class="extlink " href="#marija-slavkovik-speaker-info"><strong>Understanding Privacy by
                                    Formalising It</strong></a><br /> <em>Marija Slavkovik, University of Bergen</em>
                        </div>
                    </div>
                </div>
                <div class="item">
                    <div class="time">14:30–15:00</div>
                    <div class="item-text">
                        <div><strong>Acting for the Right Reasons: Creating Reason-Sensitive Artificial Moral
                                Agents</strong><br /> <em>Kevin Baum et al.</em></div>
                    </div>
                </div>
                <div class="item">
                    <div class="time">15:00–15:30</div>
                    <div class="item-text">Coffee Break</div>
                </div>
                <div class="item">
                    <div class="time">15:30–16:20</div>
                    <div class="item-text">
                        <div><strong>From Responsibility, via Indifference, to Recklessness</strong><br /> <em>Michael
                                Fisher</em></div>
                        <div><strong>The Need for Formal Specifications of Morally Relevant Information for Algorithmic
                                Decision-Making</strong> <span style="white-space: nowrap">(short paper)</span><br />
                            <em>Marija Slavkovik</em></div>
                    </div>
                </div>
                <div class="item">
                    <div class="time">16:20</div>
                    <div class="item-text">Community Discussion</div>
                </div>
            </div>
        </div> -->
        <h2 id="tutors" class="section"><a class="anchor" href="#tutors"
                title="permalink to this section">Tutors</a></h2>
            <div class="invited-speaker" id="marija-speaker-info">
                <div class="title-name-affiliation">
                    <div class="talk-title"><a href="/media/2025/slides-marija.pdf" target=”_blank”>What is machine ethics</a></div>
                    <div class="name-affiliation">
                        <div class="name"><a href="http://slavkovik.com/">Marija Slavkovik</a></div>
                        <div class="affiliation">University of Bergen, Norway</div>
                    </div>
                </div>
                <div class="info-and-image">
                    <div class="info-container">
                        <div class="speaker-bio">
                            <figure class="headshot-container"><img src="/media/marija-slavkovik.png"
                                    alt="Marija Slavkovik" title="Marija Slavkovik" />
                                <figcaption><a href="http://slavkovik.com/">Marija Slavkovik</a></figcaption>
                            </figure>
                            <div class="bio-text" paragraphs="none"><span>Topic</span> 
                                <p>This tutorial introduces the object of interest and methodology of the field in broad strokes. It offers an 
                                    overview of the filed developments including most impactful references,  and presents the open challenges. 
                                    This tutorial is perfect for you who is considering doing research in machine ethics. No background is necessary. 
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div> 
            <div class="invited-speaker" id="louise-speaker-info">
                <div class="title-name-affiliation">
                    <div class="talk-title"><a href="/media/2025/slides-louise.pdf" target=”_blank”>Evaluating machine ethics</a></div>
                    <div class="name-affiliation">
                        <div class="name"><a href="https://personalpages.manchester.ac.uk/staff/louise.dennis/">Louise Dennis</a></div>
                        <div class="affiliation">University of Manchester, United Kingdom</div>
                    </div>
                </div>
                <div class="info-and-image">
                    <div class="info-container">
                        <div class="speaker-bio">
                            <figure class="headshot-container"><img src="/media/2025/louise.png"
                                    alt="Louise Dennis" title="Louise Dennis" />
                                <figcaption><a href="https://personalpages.manchester.ac.uk/staff/louise.dennis/">Louise Dennis</a></figcaption>
                            </figure>
                            <div class="bio-text" paragraphs="none"><span>Topic</span>
                                <p>It is not enough that machines behave ethically. We also need to be able to prove that they do. This tutorial 
                                    focuses on formal verification for ethical behaviour. It lightly introduces formal verification and the dives 
                                    into the specific developments and challenges of the field. A background in formal verification is appreciated 
                                    but for those with a curious disposition, the tutorial is available even without it.  
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="invited-speaker" id="brian-speaker-info">
                <div class="title-name-affiliation">
                    <div class="talk-title"><a href="/media/2025/slides-logan.pdf" target=”_blank”>Reward Machines and Norms</a></div>
                    <div class="name-affiliation">
                        <div class="name"><a href="https://www.abdn.ac.uk/people/brian.logan">Brian Logan</a></div>
                        <div class="affiliation">University of Aberdeen, United Kingdom</div>
                    </div>
                </div>
                <div class="info-and-image">
                    <div class="info-container">
                        <div class="speaker-bio">
                            <figure class="headshot-container"><img src="/media/2025/brian.jpeg"
                                    alt="Brian Logan" title="Brian Logan" />
                                <figcaption><a href="https://www.abdn.ac.uk/people/brian.logan">Brian Logan</a></figcaption>
                            </figure>
                            <div class="bio-text" paragraphs="none"><span>Topic</span>
                                <p>Autonomous agents based on reinforcement learning have attracted a lot of interest. What a reinforcement 
                                    learning agent chooses to do is governed by its reward function. This tutorial introduces an approach to 
                                    specifying reward functions based on "reward machines". Reward machines allow the specification of rewards 
                                    based on the history of an agent's interaction with its environment. As such they can be used to specify 
                                    norms an agent should conform to while learning to perform another task. After briefly introducing reinforcement 
                                    learning and reward machines, we will discuss how reward machines can be used to learn to comply with norms 
                                    in a multi-agent setting. Some basic knowledge of reinforcement learning and some familiarity with formal 
                                    methods is desirable but not essential.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div> 
            <div class="invited-speaker" id="marina-speaker-info">
                <div class="title-name-affiliation">
                    <div class="talk-title"><a href="/media/2025/slides-marina.pdf" target=”_blank”>Normative multi-agent systems: An introduction</a></div>
                    <div class="name-affiliation">
                        <div class="name"><a href="https://researchportal.bath.ac.uk/en/persons/marina-de-vos">Marina De Vos</a></div>
                        <div class="affiliation">University of Bath, United Kingdom</div>
                    </div>
                </div>
                <div class="info-and-image">
                    <div class="info-container">
                        <div class="speaker-bio">
                            <figure class="headshot-container"><img src="/media/2025/marina.jpg"
                                    alt="Marina De Vos" title="Marina De Vos" />
                                <figcaption><a href="https://researchportal.bath.ac.uk/en/persons/marina-de-vos">Marina De Vos</a></figcaption>
                            </figure>
                            <div class="bio-text" paragraphs="none"><span>Topic</span>
                                <p>Norms and regulations play a fundamental role in the governance of human society. Social rules—such as laws, 
                                    conventions, and contracts—not only prescribe and regulate behavior but also allow individuals the autonomy to 
                                    violate them, accepting the consequences. This balance between guidance and discretion inspires the design of 
                                    normative multi-agent systems (NorMAS), where software agents reason about norms to make informed decisions 
                                    rather than being strictly regimented.
                                    Normative multi-agent systems provide a framework for modeling and analyzing agent behavior in environments 
                                    governed by social rules. Norms enable agents to evaluate the consequences of socially acceptable and unacceptable 
                                    actions, allowing them to choose behaviors aligned with their own goals while considering system-level 
                                    expectations.
                                    This tutorial offers an accessible introduction to normative multi-agent systems. We will introduce the InstAL 
                                    framework, which supports the modeling of normative frameworks or institutions and compliance monitoring. We 
                                    will explore topics like norm representation, enforcement, design-time and runtime verification, and the dynamics 
                                    of interacting and evolving institutions.
                                    No prior experience with multi-agents systems or normative systems is required.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div> 
        <h2 id="submission-information" class="section"><a class="anchor" href="#submission-information"
                title="permalink to this section">Registration Information</a></h2>
        <p> 
            This year we will hold a free one-day workshop with informal proceedings, consisting of short talks and opportunities for
            discussion, and a free one-day tutorial that engages conversation in the state-of-the-art machine ethics fields. 
            The workshop and tutorial will be held at Atlas room, Kilburn Building, the University of Manchester.
            <br><br>
            FEAR will be a hybrid meeting, supporting both virtual and in-person attendance. We strongly encourage in-person attendance.
            We encourage PhD candidates and interested academics to register via this 
            <a href="https://docs.google.com/forms/d/e/1FAIpQLSdHqscjYW14rdKTWH-TZ7Tw8WMA0Oybdyh4UV1GOytQPerbKQ/viewform?usp=header">link</a>. 
        </p>
        <h2 id="important-dates" class="section"><a class="anchor" href="#important-dates"
                title="permalink to this section">Important Dates</a></h2>
        <ul>
            <li>Deadline: Thursday, 11<sup>th</sup> of September 2025, 11:59 UTC-0</li>
            <!-- <li>Notification: Thursday, 11<sup>th</sup> of September 2025</li> -->
            <li>Tutorial: Monday, 3<sup>rd</sup> of November 2025</li>
        </ul>
        <h2 id="program-chair" class="section"><a class="anchor" href="#program-chair"
                title="permalink to this section">Organizers</a></h2>
                <div class="one-item-list"><strong><a href="mailto:louise.dennis@manchester.ac.uk">Louise Dennis</a></strong>, University of Manchester</div>
                <div class="one-item-list"><strong><a href="mailto:marija.slavkovik@uib.no">Marija Slavkovik</a></strong>, University of Bergen</div>
                <div class="one-item-list"><strong><a href="mailto:raynaldio.limarga@manchester.ac.uk">Raynaldio Limarga</a></strong>, University of Manchester</div>
    </div>

    <div class="horizontal-rule"></div>
    <div id="footer">
        <div class="copyright">© FEAR 2025</div>
        ⋅
        <div class="logos"><img src="/media/uom.png" title="University of Manchester" />
            <img src="/media/rae.png" title="Royal Academy of Engineering" />
            <img src="/media/kcl.png" title="King’s College London" />
            <img src="/media/cradle.png" title="Centre for Robotic Autonomy in Demanding and Long Lasting Environments (CRADLE)" />
        </div>
    </div>
</body>

</html>
